Start time: Wed Jun 11 00:13:19 CST 2025
Configuration: configs/cifar100/sdd_lskd/res32x4_res8x4.yaml
M setting: [1]
=========================================
<class 'str'>
[36m[INFO] CONFIG:
DATASET:
  NUM_WORKERS: 2
  TEST:
    BATCH_SIZE: 64
  TYPE: cifar100
DISTILLER:
  STUDENT: resnet8x4_sdd
  TEACHER: resnet32x4_sdd
  TYPE: SDD_LSKD
EXPERIMENT:
  NAME: ''
  PROJECT: cifar100_baselines
  TAG: sdd_lskd,res32x4,res8x4
LOG:
  PREFIX: ./output
  SAVE_CHECKPOINT_FREQ: 40
  TENSORBOARD_FREQ: 500
  WANDB: false
SOLVER:
  BATCH_SIZE: 64
  EPOCHS: 240
  LR: 0.05
  LR_DECAY_RATE: 0.1
  LR_DECAY_STAGES:
  - 150
  - 180
  - 210
  MOMENTUM: 0.9
  TRAINER: base
  TYPE: SGD
  WEIGHT_DECAY: 0.0005
[0m
Files already downloaded and verified
Files already downloaded and verified
[36m[INFO] Loading teacher model[0m
[1]
[1]
[36m[INFO] Extra parameters of SDD_LSKD: 0[0m[0m
Epoch 1: Training...
/root/repos/SDD-LSKD-Fusion/mdistiller/engine/utils.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location="cpu")
  Batch 100/782 - Loss CE: 4.3527, Loss KD: 0.0003
  Batch 200/782 - Loss CE: 4.1930, Loss KD: 0.0003
  Batch 300/782 - Loss CE: 4.0891, Loss KD: 0.0002
  Batch 400/782 - Loss CE: 4.0105, Loss KD: 0.0002
  Batch 500/782 - Loss CE: 3.9527, Loss KD: 0.0002
  Batch 600/782 - Loss CE: 3.8997, Loss KD: 0.0002
  Batch 700/782 - Loss CE: 3.8485, Loss KD: 0.0002
  Batch 782/782 - Loss CE: 3.8102, Loss KD: 0.0002
Epoch 1 Training Complete - Avg Loss CE: 3.8102, Avg Loss KD: 0.0002

Epoch 1 Results - Train Acc: 11.30% | Test Acc: 15.82% | Best: 15.82%
0.0037886794444444444
Epoch 2: Training...

  Batch 100/782 - Loss CE: 3.3864, Loss KD: 0.0004
  Batch 200/782 - Loss CE: 3.3564, Loss KD: 0.0004
  Batch 300/782 - Loss CE: 3.3226, Loss KD: 0.0004
  Batch 400/782 - Loss CE: 3.2813, Loss KD: 0.0004
  Batch 500/782 - Loss CE: 3.2444, Loss KD: 0.0004
  Batch 600/782 - Loss CE: 3.2049, Loss KD: 0.0004
  Batch 700/782 - Loss CE: 3.1709, Loss KD: 0.0004
  Batch 782/782 - Loss CE: 3.1421, Loss KD: 0.0004
Epoch 2 Training Complete - Avg Loss CE: 3.1421, Avg Loss KD: 0.0004

Epoch 2 Results - Train Acc: 22.06% | Test Acc: 25.46% | Best: 25.46%
0.004974333055555556
Epoch 3: Training...

  Batch 100/782 - Loss CE: 2.8610, Loss KD: 0.0005
  Batch 200/782 - Loss CE: 2.8274, Loss KD: 0.0005
  Batch 300/782 - Loss CE: 2.7878, Loss KD: 0.0005
  Batch 400/782 - Loss CE: 2.7722, Loss KD: 0.0005
  Batch 500/782 - Loss CE: 2.7377, Loss KD: 0.0005
  Batch 600/782 - Loss CE: 2.7157, Loss KD: 0.0005
  Batch 700/782 - Loss CE: 2.6978, Loss KD: 0.0005
  Batch 782/782 - Loss CE: 2.6748, Loss KD: 0.0005
Epoch 3 Training Complete - Avg Loss CE: 2.6748, Avg Loss KD: 0.0005

Epoch 3 Results - Train Acc: 31.03% | Test Acc: 31.68% | Best: 31.68%
0.004993606111111111
Epoch 4: Training...

  Batch 100/782 - Loss CE: 2.4753, Loss KD: 0.0007
  Batch 200/782 - Loss CE: 2.4478, Loss KD: 0.0007
  Batch 300/782 - Loss CE: 2.4286, Loss KD: 0.0007
  Batch 400/782 - Loss CE: 2.4128, Loss KD: 0.0007
  Batch 500/782 - Loss CE: 2.3907, Loss KD: 0.0006
  Batch 600/782 - Loss CE: 2.3797, Loss KD: 0.0006
  Batch 700/782 - Loss CE: 2.3691, Loss KD: 0.0006
  Batch 782/782 - Loss CE: 2.3559, Loss KD: 0.0006
Epoch 4 Training Complete - Avg Loss CE: 2.3559, Avg Loss KD: 0.0006

Epoch 4 Results - Train Acc: 37.66% | Test Acc: 35.41% | Best: 35.41%
0.004690450277777778
Epoch 5: Training...

  Batch 100/782 - Loss CE: 2.1705, Loss KD: 0.0008
  Batch 200/782 - Loss CE: 2.1850, Loss KD: 0.0008
  Batch 300/782 - Loss CE: 2.1728, Loss KD: 0.0008
  Batch 400/782 - Loss CE: 2.1772, Loss KD: 0.0008
  Batch 500/782 - Loss CE: 2.1596, Loss KD: 0.0008
  Batch 600/782 - Loss CE: 2.1390, Loss KD: 0.0008
  Batch 700/782 - Loss CE: 2.1346, Loss KD: 0.0008
  Batch 782/782 - Loss CE: 2.1290, Loss KD: 0.0008
Epoch 5 Training Complete - Avg Loss CE: 2.1290, Avg Loss KD: 0.0008

Epoch 5 Results - Train Acc: 42.72% | Test Acc: 35.47% | Best: 35.47%
0.004582510555555555
Epoch 6: Training...

  Batch 100/782 - Loss CE: 2.0286, Loss KD: 0.0009
  Batch 200/782 - Loss CE: 2.0400, Loss KD: 0.0009
  Batch 300/782 - Loss CE: 2.0414, Loss KD: 0.0009
  Batch 400/782 - Loss CE: 2.0237, Loss KD: 0.0009
  Batch 500/782 - Loss CE: 2.0092, Loss KD: 0.0009
  Batch 600/782 - Loss CE: 2.0000, Loss KD: 0.0009
  Batch 700/782 - Loss CE: 1.9907, Loss KD: 0.0009
  Batch 782/782 - Loss CE: 1.9855, Loss KD: 0.0009
Epoch 6 Training Complete - Avg Loss CE: 1.9855, Avg Loss KD: 0.0009

Epoch 6 Results - Train Acc: 46.10% | Test Acc: 41.36% | Best: 41.36%
0.0044021005555555555
Epoch 7: Training...

  Batch 100/782 - Loss CE: 1.8781, Loss KD: 0.0010
  Batch 200/782 - Loss CE: 1.8829, Loss KD: 0.0010
  Batch 300/782 - Loss CE: 1.8778, Loss KD: 0.0010
  Batch 400/782 - Loss CE: 1.8774, Loss KD: 0.0010
  Batch 500/782 - Loss CE: 1.8819, Loss KD: 0.0010
  Batch 600/782 - Loss CE: 1.8795, Loss KD: 0.0010
  Batch 700/782 - Loss CE: 1.8744, Loss KD: 0.0010
  Batch 782/782 - Loss CE: 1.8666, Loss KD: 0.0010
Epoch 7 Training Complete - Avg Loss CE: 1.8666, Avg Loss KD: 0.0010

Epoch 7 Results - Train Acc: 49.08% | Test Acc: 45.94% | Best: 45.94%
0.004608425
Epoch 8: Training...

  Batch 100/782 - Loss CE: 1.7736, Loss KD: 0.0011
  Batch 200/782 - Loss CE: 1.7804, Loss KD: 0.0011
  Batch 300/782 - Loss CE: 1.8003, Loss KD: 0.0011
  Batch 400/782 - Loss CE: 1.7971, Loss KD: 0.0011
  Batch 500/782 - Loss CE: 1.7917, Loss KD: 0.0011
  Batch 600/782 - Loss CE: 1.7888, Loss KD: 0.0011
  Batch 700/782 - Loss CE: 1.7855, Loss KD: 0.0011
  Batch 782/782 - Loss CE: 1.7878, Loss KD: 0.0011
Epoch 8 Training Complete - Avg Loss CE: 1.7878, Avg Loss KD: 0.0011

Epoch 8 Results - Train Acc: 50.98% | Test Acc: 46.94% | Best: 46.94%
0.004738335
Epoch 9: Training...

